active_model = "devstral-2-small"
system_prompt_id = "vibe_precision"

# REDUCE threshold to 16k. 24B models lose reasoning accuracy as context fills.
# Frequent compaction keeps the most vital instructions and recent facts "near."
auto_compact_threshold = 16000    

# DISABLE streaming. 24B models often emit malformed JSON for tool calls 
# if the stream is interrupted or tokenized poorly.
stream = false 

# --- VERIFIED NODE/NPM MCP SERVERS (No API Keys Required) ---

[[mcp_servers]]
name = "sequential_thinking"
command = "npx"
args = ["-y", "@modelcontextprotocol/server-sequential-thinking"]

[[mcp_servers]]
name = "context7"
command = "npx"
args = ["-y", "@upstash/context7-mcp"] # Verified documentation specialist

[[mcp_servers]]
name = "openwebsearch"
command = "npx"
args = ["-y", "openwebsearch"] # Free multi-engine search (No API Key)

[[mcp_servers]]
name = "filesystem"
command = "npx"
args = ["-y", "@modelcontextprotocol/server-filesystem", "."]

[[mcp_servers]]
name = "memory"
command = "npx"
args = ["-y", "@modelcontextprotocol/server-memory"] # Knowledge Graph for persistent facts

[[mcp_servers]]
name = "ripgrep"
command = "npx"
args = ["-y", "mcp-ripgrep"] # Fast local search by Matteo Collina (Node-based)

[[mcp_servers]]
name = "git"
command = "npx"
args = ["-y", "@cyanheads/git-mcp-server"] # High-repute Node.js Git wrapper

[[mcp_servers]]
name = "fetch"
command = "npx"
args = ["-y", "@modelcontextprotocol/server-fetch"] # Official URL-to-Markdown tool