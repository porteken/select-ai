active_model = "devstral-2-small"
system_prompt_id = "vibe_precision"

# REDUCE threshold to 16k to maintain Mistral 24B reasoning quality.
auto_compact_threshold = 16000    

# DISABLE streaming to prevent malformed JSON tool calls.
stream = false 

# --- LEAN MCP STACK ---

[[mcp_servers]]
name = "sequential_thinking"
command = "npx"
args = ["-y", "@modelcontextprotocol/server-sequential-thinking"]
# Why: Essential for the model to "talk to itself" and solve complex logic.

[[mcp_servers]]
name = "context7"
command = "npx"
args = ["-y", "@upstash/context7-mcp"] 
# Why: Your required documentation specialist.

[[mcp_servers]]
name = "duckduckgo"
command = "npx"
args = ["-y", "@nickclyde/duckduckgo-mcp-server"] 
# Why: Your required DuckDuckGo search.